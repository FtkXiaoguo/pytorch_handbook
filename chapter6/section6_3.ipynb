{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "section6_3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "27d80e9bd88e41ce81b263687da6a1a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6e8baceba61945c3b5a92652016a4d37",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c2a3b0c43bab4125a197cb09e09df11f",
              "IPY_MODEL_6773f48b41524b28aa9637b25d76dbd4"
            ]
          }
        },
        "6e8baceba61945c3b5a92652016a4d37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c2a3b0c43bab4125a197cb09e09df11f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9873b61ae9a744f7aeb1f387b3a2416c",
            "_dom_classes": [],
            "description": " 13%",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8d9cf6aa93b4ef58c65b8da7266106a"
          }
        },
        "6773f48b41524b28aa9637b25d76dbd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3140485efd014edca36935108921d09e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 346071040/2640397119 [00:29&lt;03:03, 12525968.20it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_03bdb9e58db04d97af050b51bf702a02"
          }
        },
        "9873b61ae9a744f7aeb1f387b3a2416c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8d9cf6aa93b4ef58c65b8da7266106a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3140485efd014edca36935108921d09e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "03bdb9e58db04d97af050b51bf702a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxmrS-k9W5ia"
      },
      "source": [
        "!git clone https://github.com/FtkXiaoguo/pytorch_handbook.git\n",
        "import sys\n",
        "sys.path.insert(1, \"/content/pytorch_handbook/chapter6\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_ybgqLyDJwh"
      },
      "source": [
        "# #colabを使う方はこちらを使用ください。\n",
        "# !pip install torch==0.4.1\n",
        "# !pip install torchvision==0.2.1\n",
        "# !pip install numpy==1.14.6\n",
        "# !pip install matplotlib==2.1.2\n",
        "# !pip install pillow==5.0.0\n",
        "# !pip install opencv-python==3.4.3.18"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JSI-ob1LXJ3"
      },
      "source": [
        "#執筆時点で存在するcolab固有のエラーを回避\n",
        "from PIL import Image\n",
        "def register_extension(id, extension): \n",
        "    Image.EXTENSION[extension.lower()] = id.upper()\n",
        "Image.register_extension = register_extension\n",
        "def register_extensions(id, extensions): \n",
        "    for extension in extensions: \n",
        "        register_extension(id, extension)\n",
        "Image.register_extensions = register_extensions"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGlfMTUfa-It"
      },
      "source": [
        "# #colabを使う方はこちらを使用ください。\n",
        "# #Google Driveにマウント\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpXhG3lzbSBK"
      },
      "source": [
        "# #colabを使う方はこちらを使用ください。※変更の必要がある場合はパスを変更してください。\n",
        "# cd /content/gdrive/My Drive/Colab Notebooks/pytorch_handbook/chapter6/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLtNvfx7bSSj"
      },
      "source": [
        "# #colabを使う方はこちらを使用ください。\n",
        "# !ls "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfdH0jXxC-pk"
      },
      "source": [
        "# パッケージのインポート\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "\n",
        "from net import weights_init, Generator, Discriminator"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAp9p1iOC-pp",
        "outputId": "9c6e4945-bfb6-43f9-fbf0-cc0f2fc129a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 設定\n",
        "workers = 2\n",
        "batch_size=50\n",
        "nz = 100\n",
        "nch_g = 64\n",
        "nch_d = 64\n",
        "n_epoch = 200\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "outf = './result_lsgan'\n",
        "display_interval = 100\n",
        "\n",
        "# 保存先ディレクトリを作成\n",
        "try:\n",
        "    os.makedirs(outf, exist_ok=True)\n",
        "except OSError as error: \n",
        "    print(error)\n",
        "    pass\n",
        "\n",
        "# 乱数のシード（種）を固定\n",
        "random.seed(0)\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fe85a19c648>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZLNaplkC-pt",
        "outputId": "fe1c07f7-669d-434f-e11a-07ef6738f923",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "27d80e9bd88e41ce81b263687da6a1a8",
            "6e8baceba61945c3b5a92652016a4d37",
            "c2a3b0c43bab4125a197cb09e09df11f",
            "6773f48b41524b28aa9637b25d76dbd4",
            "9873b61ae9a744f7aeb1f387b3a2416c",
            "c8d9cf6aa93b4ef58c65b8da7266106a",
            "3140485efd014edca36935108921d09e",
            "03bdb9e58db04d97af050b51bf702a02"
          ]
        }
      },
      "source": [
        "# STL-10のトレーニングデータセットとテストデータセットを読み込む\n",
        "trainset = dset.STL10(root='./dataset/stl10_root', download=True, split='train+unlabeled',\n",
        "                      transform=transforms.Compose([\n",
        "                          transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                          transforms.RandomHorizontalFlip(),\n",
        "                          transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                          transforms.ToTensor(),\n",
        "                          transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                      ]))   # ラベルを使用しないのでラベルなしを混在した'train+unlabeled'を読み込む\n",
        "testset = dset.STL10(root='./dataset/stl10_root', download=True, split='test',\n",
        "                     transform=transforms.Compose([\n",
        "                         transforms.RandomResizedCrop(64, scale=(88/96, 1.0), ratio=(1., 1.)),\n",
        "                         transforms.RandomHorizontalFlip(),\n",
        "                         transforms.ColorJitter(brightness=0.05, contrast=0.05, saturation=0.05, hue=0.05),\n",
        "                         transforms.ToTensor(),\n",
        "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "                     ]))\n",
        "dataset = trainset + testset    # STL-10のトレーニングデータセットとテストデータセットを合わせて訓練データとする\n",
        "\n",
        "# 訓練データをセットしたデータローダーを作成する\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=int(workers))\n",
        "\n",
        "# 学習に使用するデバイスを得る。可能ならGPUを使用する\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print('device:', device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to ./dataset/stl10_root/stl10_binary.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "27d80e9bd88e41ce81b263687da6a1a8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIJpbNtvC-pw",
        "outputId": "c6337409-9447-4cda-9fb7-7fa7a6d1997e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        }
      },
      "source": [
        "# 生成器G。ランダムベクトルから贋作画像を生成する\n",
        "netG = Generator(nz=nz, nch_g=nch_g).to(device)\n",
        "netG.apply(weights_init)    # weights_init関数で初期化\n",
        "print(netG)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): ReLU()\n",
            "    )\n",
            "    (layer4): Sequential(\n",
            "      (0): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): Tanh()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rriIYwAFC-pz",
        "outputId": "21951289-3831-490f-ad2f-55a266cca25c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "# 識別器D。画像が、元画像か贋作画像かを識別する\n",
        "netD = Discriminator(nch_d=nch_d).to(device)\n",
        "netD.apply(weights_init)\n",
        "print(netD)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (layers): ModuleDict(\n",
            "    (layer0): Sequential(\n",
            "      (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer1): Sequential(\n",
            "      (0): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer2): Sequential(\n",
            "      (0): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer3): Sequential(\n",
            "      (0): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
            "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (2): LeakyReLU(negative_slope=0.2)\n",
            "    )\n",
            "    (layer4): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1))\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjfl5HxRC-p1"
      },
      "source": [
        "criterion = nn.MSELoss()    # 損失関数は平均二乗誤差損失\n",
        "\n",
        "# オプティマイザ−のセットアップ\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 識別器D用\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999), weight_decay=1e-5)  # 生成器G用\n",
        "\n",
        "fixed_noise = torch.randn(batch_size, nz, 1, 1, device=device)  # 確認用の固定したノイズ"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lckGpHvMC-p5",
        "outputId": "44709856-a6de-4a38-99cb-407bed9b45f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2548
        }
      },
      "source": [
        "# 学習のループ\n",
        "for epoch in range(n_epoch):\n",
        "    for itr, data in enumerate(dataloader):\n",
        "        real_image = data[0].to(device)     # 元画像\n",
        "        sample_size = real_image.size(0)    # 画像枚数\n",
        "        noise = torch.randn(sample_size, nz, 1, 1, device=device)   # 正規分布からノイズを生成\n",
        "        \n",
        "        real_target = torch.full((sample_size,), 1., device=device)     # 元画像に対する識別信号の目標値「1」\n",
        "        fake_target = torch.full((sample_size,), 0., device=device)     # 贋作画像に対する識別信号の目標値「0」\n",
        "        \n",
        "        ############################\n",
        "        # 識別器Dの更新\n",
        "        ###########################\n",
        "        netD.zero_grad()    # 勾配の初期化\n",
        "\n",
        "        output = netD(real_image)   # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_real = criterion(output, real_target)  # 元画像に対する識別信号の損失値\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        fake_image = netG(noise)    # 生成器Gでノイズから贋作画像を生成\n",
        "        \n",
        "        output = netD(fake_image.detach())  # 識別器Dで元画像に対する識別信号を出力\n",
        "        errD_fake = criterion(output, fake_target)  # 贋作画像に対する識別信号の損失値\n",
        "        D_G_z1 = output.mean().item()\n",
        "\n",
        "        errD = errD_real + errD_fake    # 識別器Dの全体の損失\n",
        "        errD.backward()    # 誤差逆伝播\n",
        "        optimizerD.step()   # Dのパラメーターを更新\n",
        "\n",
        "        ############################\n",
        "        # 生成器Gの更新\n",
        "        ###########################\n",
        "        netG.zero_grad()    # 勾配の初期化\n",
        "        \n",
        "        output = netD(fake_image)   # 更新した識別器Dで改めて贋作画像に対する識別信号を出力\n",
        "        errG = criterion(output, real_target)   # 生成器Gの損失値。Dに贋作画像を元画像と誤認させたいため目標値は「1」\n",
        "        errG.backward()     # 誤差逆伝播\n",
        "        D_G_z2 = output.mean().item()\n",
        "\n",
        "        optimizerG.step()   # Gのパラメータを更新\n",
        "\n",
        "        if itr % display_interval == 0: \n",
        "            print('[{}/{}][{}/{}] Loss_D: {:.3f} Loss_G: {:.3f} D(x): {:.3f} D(G(z)): {:.3f}/{:.3f}'\n",
        "                  .format(epoch + 1, n_epoch,\n",
        "                          itr + 1, len(dataloader),\n",
        "                          errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "        if epoch == 0 and itr == 0:     # 初回に元画像を保存する\n",
        "            vutils.save_image(real_image, '{}/real_samples.png'.format(outf),\n",
        "                              normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # 確認用画像の生成\n",
        "    ############################\n",
        "    fake_image = netG(fixed_noise)  # 1エポック終了ごとに確認用の贋作画像を生成する\n",
        "    vutils.save_image(fake_image.detach(), '{}/fake_samples_epoch_{:03d}.png'.format(outf, epoch + 1),\n",
        "                      normalize=True, nrow=10)\n",
        "\n",
        "    ############################\n",
        "    # モデルの保存\n",
        "    ############################\n",
        "    if (epoch + 1) % 50 == 0:   # 50エポックごとにモデルを保存する\n",
        "        torch.save(netG.state_dict(), '{}/netG_epoch_{}.pth'.format(outf, epoch + 1))\n",
        "        torch.save(netD.state_dict(), '{}/netD_epoch_{}.pth'.format(outf, epoch + 1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1/200][1/2260] Loss_D: 3.741 Loss_G: 18.051 D(x): 0.302 D(G(z)): -0.523/5.165\n",
            "[1/200][101/2260] Loss_D: 20.945 Loss_G: 26.064 D(x): 0.277 D(G(z)): -4.417/6.065\n",
            "[1/200][201/2260] Loss_D: 0.717 Loss_G: 3.240 D(x): 1.152 D(G(z)): 0.708/-0.774\n",
            "[1/200][301/2260] Loss_D: 0.165 Loss_G: 1.134 D(x): 1.023 D(G(z)): 0.065/-0.045\n",
            "[1/200][401/2260] Loss_D: 0.221 Loss_G: 1.738 D(x): 1.114 D(G(z)): 0.253/-0.307\n",
            "[1/200][501/2260] Loss_D: 0.227 Loss_G: 1.130 D(x): 1.033 D(G(z)): 0.290/-0.048\n",
            "[1/200][601/2260] Loss_D: 0.209 Loss_G: 0.860 D(x): 1.047 D(G(z)): 0.265/0.096\n",
            "[1/200][701/2260] Loss_D: 0.180 Loss_G: 0.825 D(x): 0.831 D(G(z)): 0.160/0.108\n",
            "[1/200][801/2260] Loss_D: 0.221 Loss_G: 0.572 D(x): 0.709 D(G(z)): -0.087/0.270\n",
            "[1/200][901/2260] Loss_D: 0.205 Loss_G: 1.215 D(x): 1.013 D(G(z)): 0.333/-0.086\n",
            "[1/200][1001/2260] Loss_D: 0.103 Loss_G: 0.672 D(x): 0.780 D(G(z)): 0.028/0.194\n",
            "[1/200][1101/2260] Loss_D: 0.168 Loss_G: 1.408 D(x): 1.174 D(G(z)): 0.217/-0.179\n",
            "[1/200][1201/2260] Loss_D: 0.096 Loss_G: 1.286 D(x): 0.937 D(G(z)): 0.102/-0.119\n",
            "[1/200][1301/2260] Loss_D: 0.089 Loss_G: 1.154 D(x): 0.968 D(G(z)): 0.096/-0.063\n",
            "[1/200][1401/2260] Loss_D: 0.181 Loss_G: 0.572 D(x): 0.703 D(G(z)): 0.009/0.277\n",
            "[1/200][1501/2260] Loss_D: 0.124 Loss_G: 1.035 D(x): 0.867 D(G(z)): 0.210/-0.009\n",
            "[1/200][1601/2260] Loss_D: 0.345 Loss_G: 1.818 D(x): 1.163 D(G(z)): 0.438/-0.308\n",
            "[1/200][1701/2260] Loss_D: 0.271 Loss_G: 1.706 D(x): 1.224 D(G(z)): 0.333/-0.291\n",
            "[1/200][1801/2260] Loss_D: 0.097 Loss_G: 1.048 D(x): 0.916 D(G(z)): -0.006/-0.009\n",
            "[1/200][1901/2260] Loss_D: 0.175 Loss_G: 0.861 D(x): 0.784 D(G(z)): 0.145/0.084\n",
            "[1/200][2001/2260] Loss_D: 0.115 Loss_G: 0.806 D(x): 0.764 D(G(z)): 0.061/0.113\n",
            "[1/200][2101/2260] Loss_D: 0.172 Loss_G: 0.794 D(x): 0.821 D(G(z)): 0.126/0.133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnVHkaZAR7bp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}